# EGformer

This repository contains the code of the paper 
>["EGformer: Equirectangular geometry-biased transformer for 360 monocular depth estimation."](https://arxiv.org/abs/2304.07803)  
>
>Ilwi Yun, Chanyong Shin, Hyunku Lee, Hyuk-Jae Lee, Chae Eun Rhee.
>
>ICCV2023

Our codes are based on the following repositories: [CSWin Transformer](https://github.com/microsoft/CSWin-Transformer), [Panoformer](https://github.com/zhijieshen-bjtu/PanoFormer), [MiDaS](https://github.com/isl-org/MiDaS), [Pano3D](https://github.com/VCL3D/Pano3D).

We'd like to thank the authors and users providing the codes.

**Codes, instructions, citations, etc. will be uploaded soon after the conference.**

## :blue_book: Experiment Report 
To check the reproducibility, we re-trained some models in the paper under slightly different environment, and log the training progress of them. 
Some additional experiments are also conducted for further analysis, which can be found in this [:blue_book: ***EGformer Report***](https://api.wandb.ai/links/yuniw/21nqqyl8). 


## To do list
- [x] Experiment report  
- [ ] Code for inference  
- [ ] Code for evaluation 
- [ ] Code for training

## Citation
```
@article{yun2023egformer,
  title={EGformer: Equirectangular Geometry-biased Transformer for 360 Depth Estimation},
  author={Yun, Ilwi and Shin, Chanyong and Lee, Hyunku and Lee, Hyuk-Jae and Rhee, Chae Eun},
  journal={arXiv preprint arXiv:2304.07803},
  year={2023}
}
```
## License
Our contributions on codes are released under the MIT license. For the codes of the otehr works, refer to their repositories.
